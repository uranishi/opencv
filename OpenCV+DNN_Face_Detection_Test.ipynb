{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "HGv_P9HPULDJ",
        "kTFzTTfgMJb_",
        "9KuXsfTZ0U-l",
        "IZxEKZtx7Uzh",
        "-t02VngCFmq7",
        "UpjScVfzNBUa",
        "s1BTe_BD425Y",
        "_W09NayxCTNP",
        "kTKx08EfSux0",
        "eB4-dTuZM5Iq",
        "nqcU5xQzUiJh",
        "PDhkZXHhU5Ak",
        "xxvtf0RpVZ1Q",
        "35rlp1Gy5f6K",
        "8ghmFtxm5sbP",
        "NmeaLLoi5y2V",
        "R61EhOwx55ye",
        "4GW-14xy6m7Y",
        "A5LfZkFt7sqG",
        "QGDDmQcw6m7v",
        "vfKwkKY96ZQ8",
        "2oppuZsj7NXa",
        "2KwNZbJI7NXH"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uranishi/opencv/blob/master/OpenCV%2BDNN_Face_Detection_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inf9GggVQwg8"
      },
      "source": [
        "# Google Colaboratory+OpenCVでWebカメラ画像から顔検出\n",
        "\n",
        "この記事の元となっているプログラムである．\n",
        "https://qiita.com/uranishi/items/85184baf1df33192e00a\n",
        "\n",
        "Thanks to: \n",
        "https://colab.research.google.com/github/dortmans/ml_notebooks/blob/master/face_detection.ipynb#scrollTo=UZp-xlhYI1SL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISLuBUchaHK1"
      },
      "source": [
        "## ヘッダ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1A98mDFjim9"
      },
      "source": [
        "# Google Driveをマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# imshowサポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# dnn用\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "# その他パッケージ\n",
        "import imutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZptdWjJaDbc"
      },
      "source": [
        "## カメラ入力モジュール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2_7lK-akIN5"
      },
      "source": [
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edxt2NgWa9a3"
      },
      "source": [
        "## ネットワークと学習済みモジュールをダウンロード"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBuOakMnTyCy"
      },
      "source": [
        "- deploy.prototxt: ネットワーク\n",
        "- res10_300x300_ssd_iter_140000.caffemodel: 学習済みモデル"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4NwCZBhTie7"
      },
      "source": [
        "!wget -N https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt\n",
        "!wget -N https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samples_face_detector_20170830/res10_300x300_ssd_iter_140000.caffemodel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_e11fahWZQdt"
      },
      "source": [
        "## メインの顔検出モジュール"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EvhQAoobhaQ"
      },
      "source": [
        "### 画像をカメラからキャプチャ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICF3ti3nkIN5"
      },
      "source": [
        "try:\n",
        "  filename = take_photo()\n",
        "  img = cv2.imread(filename)\n",
        "  print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  #display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrSxJZCLcKkm"
      },
      "source": [
        "### ダウンロードしたネットワークとモデルを読み込む"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2xn3A5EUQY-"
      },
      "source": [
        "# ネットワークと学習済みモデルをロードする\n",
        "print(\"[INFO] loading model...\")\n",
        "prototxt = 'deploy.prototxt'\n",
        "model = 'res10_300x300_ssd_iter_140000.caffemodel'\n",
        "net = cv2.dnn.readNetFromCaffe(prototxt, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZX4TsEIvcoOi"
      },
      "source": [
        "### 読み込んだ画像をリサイズし，blobを作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xrs7Lk_X1uek"
      },
      "source": [
        "# 幅400画素になるようにリサイズする\n",
        "img = imutils.resize(img, width=400)\n",
        "(h, w) = img.shape[:2]\n",
        "blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QEUOAEZdLb5"
      },
      "source": [
        "### ネットワークにblobを通す"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF3EhuvS5j53"
      },
      "source": [
        "# 物体検出器にblobを適用する\n",
        "print(\"[INFO] computing object detections...\")\n",
        "net.setInput(blob)\n",
        "detections = net.forward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iU55ME6dX1f"
      },
      "source": [
        "### confidenceが0.5を超える領域をマークする"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AozMWEAb6Kr7"
      },
      "source": [
        "for i in range(0, detections.shape[2]):\n",
        "\n",
        "  # ネットワークが出力したconfidenceの値を抽出する\n",
        "\tconfidence = detections[0, 0, i, 2]\n",
        "\n",
        "  # confidenceの値が0.5以上の領域のみを検出結果として描画する\n",
        "\tif confidence > 0.5:\n",
        "\t\t# 対象領域のバウンディングボックスの座標を計算する\n",
        "\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\t\t# バウンディングボックスとconfidenceの値を描画する\n",
        "\t\ttext = \"{:.2f}%\".format(confidence * 100)\n",
        "\t\ty = startY - 10 if startY - 10 > 10 else startY + 10\n",
        "\t\tcv2.rectangle(img, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
        "\t\tcv2.putText(img, text, (startX, y),\n",
        "\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WICWY6_7p6b"
      },
      "source": [
        "# 出力結果を表示して保存\n",
        "cv2_imshow(img)\n",
        "cv2.imwrite(\"/content/gdrive/My Drive/Works_OpenCV/OpenCV_Colaboratory/dnn_face_out.jpg\", img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}